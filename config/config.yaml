# Configuration file for training a model using PyTorch Lightning.
# Contains model, data, training, and logging configurations.

seed_everything: 42  # Seed for reproducibility across experiments
ckpt_path: null      # Checkpoint path (set to null to start from scratch)

# Anchor definitions for num_classes and image dimensions
num_classes: &num_classes 42
image_height: &image_height 224
image_width: &image_width 224

experiment:
  custom_folder_name: null # Custom folder name for storing experiment data
  only_weights_load: false           # Flag to load only model weights from a checkpoint

model:
  model:
    class_path: models.models.ImageClassification  # Path to the model class
    init_args:
      model_name: google/efficientnet-b3            # Pre-trained model name
      num_classes: *num_classes                     # Number of classes for output layer
      freeze_encoder: true                          # Freeze encoder layers for transfer learning
      optimizer_config:
        scheduler: ReduceLROnPlateau
        lr:  0.05

  # Loss function configuration
  loss_fn:
    class_path: torch.nn.CrossEntropyLoss           # Loss function class path
    init_args: {}                                   # No additional parameters for CrossEntropyLoss

# Common transformations for normalization and resizing
common_transforms: &common_transforms
  - class_path: dataset_modules.augmentations.Resize
    init_args:
      height: *image_height                         # Use the image height anchor
      width: *image_width                           # Use the image width anchor

  - class_path: dataset_modules.augmentations.Normalize
    init_args:
      mean: [0.485, 0.456, 0.406]                   # Mean for each RGB channel
      std: [0.478, 0.473, 0.474]                    # Standard deviation for each RGB channel
      max_pixel_value: 255.0                        # Max pixel value for normalization

  - class_path: albumentations.pytorch.transforms.ToTensorV2
    init_args: {}                                   # Convert image to PyTorch tensor

data:
  num_workers: 8                                    # Number of data loading workers
  batch_size: 64                                    # Batch size for training
  create_dataset: false                             # If true, will create the dataset from scratch

  dataset_classes:
    - class_path: dataset_modules.folder_image_dataset.FolderImageDataset
      init_args:
        train_val_dir: "data/train/simpsons_dataset"      # Directory for training and validation data

  normalizations: *common_transforms                # Reuse normalizations defined in common_transforms
  augmentations: *common_transforms                 # Reuse augmentations defined in common_transforms

# Common metric arguments for consistent metric setup
metric_common_args: &metric_common_args
  task: multiclass                                  # Metric type for multiclass classification
  average: "macro"                                  # Average type for metric calculation
  num_classes: *num_classes                         # Total number of classes

trainer:
  accelerator: "gpu"                                # Hardware accelerator to use
  devices: [0]                                      # GPU device ID(s) to use
  max_epochs: 50                                    # Maximum number of training epochs
  precision: 16                                     # Mixed precision training (16-bit)
  limit_train_batches: 1.0                          # Fraction of training batches to use per epoch
  limit_val_batches: 1.0                            # Fraction of validation batches to use per epoch
  fast_dev_run: false                               # Run a fast dev test, e.g., for debugging

  # Callback configurations
  callbacks:
    # Periodic checkpoint saving configuration
    - class_path: toolkit.callbacks.PeriodicCheckpointSaver
      init_args:
        dirpath: "checkpoints"                      # Directory for saving checkpoints
        filename: "{epoch:02d}-{validation_f1_score:.4f}"  # Filename format for checkpoints
        monitor: "validation_f1_score"              # Metric to monitor for saving
        mode: "max"                                 # Maximize the monitored metric
        save_top_k: 3                               # Number of top checkpoints to keep
        verbose: true                               # Log checkpoint saving

    # Metrics logger configuration for multiple metrics
    - class_path: toolkit.callbacks.MetricsLoggerCallback
      init_args:
        metrics:
          accuracy:
            class_path: torchmetrics.Accuracy
            init_args:
              <<: *metric_common_args               # Reuse common metric arguments

          precision:
            class_path: torchmetrics.Precision
            init_args:
              <<: *metric_common_args

          recall:
            class_path: torchmetrics.Recall
            init_args:
              <<: *metric_common_args

          f1_score:
            class_path: torchmetrics.F1Score
            init_args:
              <<: *metric_common_args

    # Progress bar for training
    - class_path: pytorch_lightning.callbacks.TQDMProgressBar
      init_args:
        refresh_rate: 5                             # Update rate for progress bar

    # Early stopping configuration
    - class_path: pytorch_lightning.callbacks.EarlyStopping
      init_args:
        monitor: "validation_f1_score"              # Metric to monitor for stopping
        mode: "max"                                 # Stop when maximizing the metric
        patience: 10                                # Number of epochs with no improvement before stopping
        verbose: true                               # Log early stopping
